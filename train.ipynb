{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet \n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"./train.csv\")\n",
    "val=pd.read_csv(\"./validation.csv\")\n",
    "test=pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Model (tfidf tokenizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train.X_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4512, 7330), (502, 7330))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagofwords=vectorizer.vocabulary_\n",
    "X_train=vectorizer.transform(train.X_train)\n",
    "X_val=vectorizer.transform(val.X_val)\n",
    "X_test=vectorizer.transform(test.X_test)\n",
    "print(len(bagofwords))\n",
    "X_train.shape,X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4512, 7330), (502, 7330))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(X_train)\n",
    "X_train_tfidf=tfidf_transformer.transform(X_train)\n",
    "X_val_tfidf=tfidf_transformer.transform(X_val)\n",
    "X_test_tfidf=tfidf_transformer.transform(X_test)\n",
    "X_train_tfidf.shape,X_val_tfidf.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99       441\n",
      "        spam       0.98      0.92      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.99      0.96      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9900398406374502 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99       441\n",
      "        spam       1.00      0.92      0.96        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.99      0.96      0.98       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99       441\n",
      "        spam       1.00      0.90      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.99      0.95      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9820717131474104 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       441\n",
      "        spam       1.00      0.85      0.92        61\n",
      "\n",
      "    accuracy                           0.98       502\n",
      "   macro avg       0.99      0.93      0.96       502\n",
      "weighted avg       0.98      0.98      0.98       502\n",
      "\n",
      "0.9741035856573705 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99       441\n",
      "        spam       1.00      0.79      0.88        61\n",
      "\n",
      "    accuracy                           0.97       502\n",
      "   macro avg       0.99      0.89      0.93       502\n",
      "weighted avg       0.97      0.97      0.97       502\n",
      "\n",
      "0.9721115537848606 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98       441\n",
      "        spam       1.00      0.77      0.87        61\n",
      "\n",
      "    accuracy                           0.97       502\n",
      "   macro avg       0.98      0.89      0.93       502\n",
      "weighted avg       0.97      0.97      0.97       502\n",
      "\n",
      "0.9641434262948207 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       441\n",
      "        spam       1.00      0.70      0.83        61\n",
      "\n",
      "    accuracy                           0.96       502\n",
      "   macro avg       0.98      0.85      0.90       502\n",
      "weighted avg       0.97      0.96      0.96       502\n",
      "\n",
      "0.9561752988047809 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      1.00      0.98       441\n",
      "        spam       1.00      0.64      0.78        61\n",
      "\n",
      "    accuracy                           0.96       502\n",
      "   macro avg       0.98      0.82      0.88       502\n",
      "weighted avg       0.96      0.96      0.95       502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.25, 2.25, 0.25):\n",
    "    spam_detector = MultinomialNB(alpha=i).fit(X_train_tfidf, train.y_train)\n",
    "    y_pred = spam_detector.predict(X_val_tfidf)\n",
    "    print(accuracy_score(val.y_val, y_pred), '\\n', classification_report(val.y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alpha = 0.5 gives best results. It maximises accuracy and recall for Spam mails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detector = MultinomialNB(alpha=0.5).fit(X_train_tfidf, train.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900398406374502"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = spam_detector.predict(X_val_tfidf)\n",
    "accuracy_score(val.y_val, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99       441\n",
      "        spam       1.00      0.92      0.96        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.99      0.96      0.98       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val.y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9731182795698925"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = spam_detector.predict(X_test_tfidf)\n",
    "accuracy_score(test.y_test, y_pred_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98       485\n",
      "        spam       1.00      0.79      0.89        73\n",
      "\n",
      "    accuracy                           0.97       558\n",
      "   macro avg       0.98      0.90      0.94       558\n",
      "weighted avg       0.97      0.97      0.97       558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test.y_test, y_pred_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Model (Count tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4512, 7330), (502, 7330))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagofwords=vectorizer.vocabulary_\n",
    "X_train=vectorizer.transform(train.X_train)\n",
    "X_val=vectorizer.transform(val.X_val)\n",
    "X_test=vectorizer.transform(test.X_test)\n",
    "print(len(bagofwords))\n",
    "X_train.shape,X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9860557768924303 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.94      0.95      0.94        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.96      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.25, 2.25, 0.25):\n",
    "    spam_detector = MultinomialNB(alpha=i).fit(X_train, train.y_train)\n",
    "    y_pred = spam_detector.predict(X_val)\n",
    "    print(accuracy_score(val.y_val, y_pred), '\\n', classification_report(val.y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model performs similar for all values of alpha from 0.5 to 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(C=1)\n",
    "clf.fit(X_train_tfidf, train.y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = clf.predict(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(val.y_val, y_pred), '\\n', classification_report(val.y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n",
      "0.9880478087649402 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       441\n",
      "        spam       0.95      0.95      0.95        61\n",
      "\n",
      "    accuracy                           0.99       502\n",
      "   macro avg       0.97      0.97      0.97       502\n",
      "weighted avg       0.99      0.99      0.99       502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10000,1000):\n",
    "    clf = SVC(C=i)\n",
    "    clf.fit(X_train_tfidf, train.y_train)\n",
    "    y_predicted = clf.predict(X_val_tfidf)\n",
    "    print(accuracy_score(val.y_val, y_pred), '\\n', classification_report(val.y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performs similar for the different values of regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes Model (tfidf tokenizer) performs best, out of the three model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "213524bb45a1aeaf737b1d8c77d7b8db5d425938d9dffc5f4bc6fe6dd3324700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
